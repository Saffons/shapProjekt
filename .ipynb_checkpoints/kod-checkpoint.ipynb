{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "wrapped-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import shap\n",
    "from shap.plots import *\n",
    "import csv\n",
    "import nltk\n",
    "import re, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fifteen-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\'','', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "portuguese-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date from string to datetime object\n",
    "def datte():\n",
    "    for i in range(len(train)):\n",
    "        train['date'][i] = datetime.datetime.strptime(train['date'][i], '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "# select n random tweets from start date to end date\n",
    "def choose_tweets_from_date(start, end, n):\n",
    "    start = datetime.datetime.strptime(start, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "    choices = []\n",
    "    for i in range(len(train)):\n",
    "        if start <= train['date'][i] <= end:\n",
    "            el = []\n",
    "            el.append([train['content'][i], i])\n",
    "            choices.append(el)\n",
    "        \n",
    "    \n",
    "    chosen = []\n",
    "    chosen.append(random.sample(choices, n))\n",
    "\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "numerous-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('WFiIS-MIO-main/datasets/realdonaldtrump.csv')\n",
    "train = train.drop(['link', 'retweets', 'favorites', 'mentions', 'hashtags'], axis=1)\n",
    "\n",
    "train['content'] = train['content'].map(lambda x: re.sub(r'@\\w+\\s', ' ', x))\n",
    "train['content'] = train['content'].map(lambda x: re.sub(r'https?://\\S+|www\\.\\S+', '', x))\n",
    "train['content'] = train['content'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "train['content'] = train['content'].replace(r'\\W+', ' ', regex=True)\n",
    "train['content'] = train['content'].apply(lambda x:clean_text(x))\n",
    "train['token'] = train['content'].apply(lambda x:word_tokenize(x))\n",
    "train['text'] = train['token'].apply(lambda x: ' '.join([word for word in x if len(word)>2]))\n",
    "datte()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "educated-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{' jheil at nymag is such a pathetic reporter who doesn t want to know the truth a total obama flunky hack ': 7332}],\n",
       " [{'  donald trump leads in new gop polls foxandfriends realdonaldtrump pic twitter com  ': 24310}],\n",
       " [{' ianjamespoulter great going and almost as importantly your clothing line is selling well ': 17509}],\n",
       " [{'they laughed at me when i said to bomb the isis controlled oil fields now they are not laughing and doing what i said ': 26232}],\n",
       " [{' makeamericagreatagain  twitter com ': 27028}],\n",
       " [{'i had a great time in texas yesterday a tremendous crowd of wonderful and enthusiastic people will be back soon ': 26260}],\n",
       " [{' mccareydanny realdonaldtrump how come nbc is screwing theapprentice by burning off episodes so fast only one hour each ': 19853}],\n",
       " [{'with all that is happening with ebola including the doctor who so easily came back to new york obama still refuses to stop the flights ': 18032}],\n",
       " [{'i will be interviewed by jdickerson on facethenation tomorrow morning enjoy ': 28557}],\n",
       " [{'bill kristol has been wrong for  an embarrassed loser but if the gop can t control their own then they are not a party be tough r s ': 29128}],\n",
       " [{'get all the info then quick trial then death penalty for the boston killer of innocent children and people do not be kind ': 8374}],\n",
       " [{'if obama worked as hard on straightening out our country as he has trying to protect and elect hillary we would all be much better off ': 30847}],\n",
       " [{'enjoy the super bowl ': 13833}],\n",
       " [{' maddow you copied incompetent katyturnbc incorrect story i m sure you would like to apologize to me on show thank you for the courtesy ': 26658}],\n",
       " [{' johnberman two explanations on realdonaldtrump that seem no longer sufficient  it s early  it is all a media creation ': 24599}],\n",
       " [{'  realdonaldtrump for president in  ': 18699}],\n",
       " [{'why do we continue to sit idly by while china steals our national security and corporate secrets china is an enemy not a friend ': 685}],\n",
       " [{'secy john kerry has a tough job but he looks so totally lost negotiating w those characters who are cleaning his clock sad to watch ': 16155}],\n",
       " [{'one of my first acts as president will be to deport the drug lords and then secure the border debate maga': 30606}],\n",
       " [{'  realdonaldtrump great show this season luv the back to back episodes great cast this time ': 19845}],\n",
       " [{'so much for hope change democrat voter enthusiasm in  is lower than both  ': 2655}],\n",
       " [{'congratulations to our olympic team for by far winning the most medals including first place gold ': 2819}],\n",
       " [{' warrencasselljr you re exactly what america needs mr trump realdonaldtrump thanks ': 9492}],\n",
       " [{' tjohnsontj realdonaldtrump you have my vote in my first election great debate last night keep up the good work  thanks ': 25873}],\n",
       " [{'after these spirited primaries are over gop must be fully united for november if we take the senate we stop obama s agenda ': 16162}],\n",
       " [{'can you believe that sony chief amy pascal wants to meet with al sharpton to seek forgiveness for her racial slurs al is laughing at her ': 19098}],\n",
       " [{'fires its employees builds a new factory or plant in the other country and then thinks it will sell its product back into the u s ': 30998}],\n",
       " [{'will be interviewed on foxandfriends now ': 29877}],\n",
       " [{'president obama was able to fool the americans by getting elected but not able to fool vladimir putin too bad for us ': 14387}],\n",
       " [{'  congratulations and all the best to you ': 4730}],\n",
       " [{' magicmetalninja the trump movement will not be stopped we support trump because he is a true american looking out for americafirst ': 29021}],\n",
       " [{'when in doubt obama fundraises he has held  fundraisers in six years another record ': 16641}],\n",
       " [{'china is driving the price of gold up in order to ease pressure against iranian sanctions ': 1097}],\n",
       " [{' rghilinoclu i bought a couple beautiful realdonaldtrump ties at macys today guaranteed to look sharp this week ': 13587}],\n",
       " [{'to vote for me and century  for the best superbowl commercial click the following link and like the page ': 1277}],\n",
       " [{' foxnews you shouldn t have karlrove on the air he s a clown with zero credibility a bushy ': 23945}],\n",
       " [{' thanks ': 5559}],\n",
       " [{'  the success of donald trump read on ': 20902}],\n",
       " [{'  trumpdoral realdonaldtrump one beautiful course thank you ': 15429}],\n",
       " [{' however beautiful the strategy you should occasionally look at the results winston churchill': 2485}],\n",
       " [{' ustechie realdonaldtrump what are you doing with old post office in washingtondc and when we are going to build the finest hotel in c ': 9405}],\n",
       " [{'another solar company barackobama funded with our money has filed for bankruptcy one cont ': 1730}],\n",
       " [{'wow what a great honor from drudgereport ': 24483}],\n",
       " [{'my foxnews interview with teamcavuto discussing the newsmax iontv debate timetogettough and the  race': 895}],\n",
       " [{' makeamericaworkagain  rncincle pic twitter com ': 29601}],\n",
       " [{'via advisorsource donald trump speaks in novi drawing largest crowd in oakland county republican party s history ': 9200}],\n",
       " [{' jenkingporter realdonaldtrump brandiglanville brandi should win i hope kate and geraldo get kicked off soon ': 19791}],\n",
       " [{' memeoryhead i m one of your biggest fans mr trump and i can t wait for you to make america great ifagain never forget you have support ': 27178}],\n",
       " [{' you don t necessarily need the best location what you need is the best deal the art of the deal': 10247}],\n",
       " [{' thesisko realdonaldtrump you have to run on  thanks ': 7349}]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 50\n",
    "before = choose_tweets_from_date('2011-01-01', '2017-01-19', n)\n",
    "after = choose_tweets_from_date('2017-01-20', '2021-01-20', n)\n",
    "before[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "elect-diameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0e6a_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f0e6a_row1_col1 {\n",
       "  background-color: #6fb0d7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f0e6a_row2_col1 {\n",
       "  background-color: #a5cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row3_col1 {\n",
       "  background-color: #a9cfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row4_col1 {\n",
       "  background-color: #c1d9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row5_col1 {\n",
       "  background-color: #c6dbef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row6_col1 {\n",
       "  background-color: #cddff1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row7_col1, #T_f0e6a_row8_col1 {\n",
       "  background-color: #d4e4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row9_col1 {\n",
       "  background-color: #d9e8f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row10_col1 {\n",
       "  background-color: #e3eef8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row11_col1 {\n",
       "  background-color: #e7f0fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row12_col1 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row13_col1 {\n",
       "  background-color: #eef5fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row14_col1, #T_f0e6a_row15_col1 {\n",
       "  background-color: #eff6fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row16_col1 {\n",
       "  background-color: #f0f6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row17_col1 {\n",
       "  background-color: #f2f8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f0e6a_row18_col1, #T_f0e6a_row19_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0e6a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f0e6a_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_f0e6a_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f0e6a_row0_col0\" class=\"data row0 col0\" >the</td>\n",
       "      <td id=\"T_f0e6a_row0_col1\" class=\"data row0 col1\" >34657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f0e6a_row1_col0\" class=\"data row1 col0\" >to</td>\n",
       "      <td id=\"T_f0e6a_row1_col1\" class=\"data row1 col1\" >19801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f0e6a_row2_col0\" class=\"data row2 col0\" >and</td>\n",
       "      <td id=\"T_f0e6a_row2_col1\" class=\"data row2 col1\" >15928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f0e6a_row3_col0\" class=\"data row3 col0\" >a</td>\n",
       "      <td id=\"T_f0e6a_row3_col1\" class=\"data row3 col1\" >15491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f0e6a_row4_col0\" class=\"data row4 col0\" >of</td>\n",
       "      <td id=\"T_f0e6a_row4_col1\" class=\"data row4 col1\" >13345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f0e6a_row5_col0\" class=\"data row5 col0\" >is</td>\n",
       "      <td id=\"T_f0e6a_row5_col1\" class=\"data row5 col1\" >12886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f0e6a_row6_col0\" class=\"data row6 col0\" >in</td>\n",
       "      <td id=\"T_f0e6a_row6_col1\" class=\"data row6 col1\" >11942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f0e6a_row7_col0\" class=\"data row7 col0\" >i</td>\n",
       "      <td id=\"T_f0e6a_row7_col1\" class=\"data row7 col1\" >10795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f0e6a_row8_col0\" class=\"data row8 col0\" >you</td>\n",
       "      <td id=\"T_f0e6a_row8_col1\" class=\"data row8 col1\" >10716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f0e6a_row9_col0\" class=\"data row9 col0\" >for</td>\n",
       "      <td id=\"T_f0e6a_row9_col1\" class=\"data row9 col1\" >9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f0e6a_row10_col0\" class=\"data row10 col0\" >realdonaldtrump</td>\n",
       "      <td id=\"T_f0e6a_row10_col1\" class=\"data row10 col1\" >8638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f0e6a_row11_col0\" class=\"data row11 col0\" >on</td>\n",
       "      <td id=\"T_f0e6a_row11_col1\" class=\"data row11 col1\" >8027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f0e6a_row12_col0\" class=\"data row12 col0\" >s</td>\n",
       "      <td id=\"T_f0e6a_row12_col1\" class=\"data row12 col1\" >7394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f0e6a_row13_col0\" class=\"data row13 col0\" >be</td>\n",
       "      <td id=\"T_f0e6a_row13_col1\" class=\"data row13 col1\" >6934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f0e6a_row14_col0\" class=\"data row14 col0\" >it</td>\n",
       "      <td id=\"T_f0e6a_row14_col1\" class=\"data row14 col1\" >6837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f0e6a_row15_col0\" class=\"data row15 col0\" >great</td>\n",
       "      <td id=\"T_f0e6a_row15_col1\" class=\"data row15 col1\" >6755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f0e6a_row16_col0\" class=\"data row16 col0\" >will</td>\n",
       "      <td id=\"T_f0e6a_row16_col1\" class=\"data row16 col1\" >6678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f0e6a_row17_col0\" class=\"data row17 col0\" >that</td>\n",
       "      <td id=\"T_f0e6a_row17_col1\" class=\"data row17 col1\" >6295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f0e6a_row18_col0\" class=\"data row18 col0\" >are</td>\n",
       "      <td id=\"T_f0e6a_row18_col1\" class=\"data row18 col1\" >5672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0e6a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_f0e6a_row19_col0\" class=\"data row19 col0\" >trump</td>\n",
       "      <td id=\"T_f0e6a_row19_col1\" class=\"data row19 col1\" >5604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x186c88b1340>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = Counter([item for sublist in train['token'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "interior-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "the",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "the",
         "offsetgroup": "the",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          34657
         ],
         "xaxis": "x",
         "y": [
          "the"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "to",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "to",
         "offsetgroup": "to",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          19801
         ],
         "xaxis": "x",
         "y": [
          "to"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "and",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "and",
         "offsetgroup": "and",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          15928
         ],
         "xaxis": "x",
         "y": [
          "and"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "a",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "a",
         "offsetgroup": "a",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          15491
         ],
         "xaxis": "x",
         "y": [
          "a"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "of",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "of",
         "offsetgroup": "of",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          13345
         ],
         "xaxis": "x",
         "y": [
          "of"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "is",
         "marker": {
          "color": "#19d3f3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "is",
         "offsetgroup": "is",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          12886
         ],
         "xaxis": "x",
         "y": [
          "is"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "in",
         "marker": {
          "color": "#FF6692",
          "pattern": {
           "shape": ""
          }
         },
         "name": "in",
         "offsetgroup": "in",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          11942
         ],
         "xaxis": "x",
         "y": [
          "in"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "i",
         "marker": {
          "color": "#B6E880",
          "pattern": {
           "shape": ""
          }
         },
         "name": "i",
         "offsetgroup": "i",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          10795
         ],
         "xaxis": "x",
         "y": [
          "i"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "you",
         "marker": {
          "color": "#FF97FF",
          "pattern": {
           "shape": ""
          }
         },
         "name": "you",
         "offsetgroup": "you",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          10716
         ],
         "xaxis": "x",
         "y": [
          "you"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "for",
         "marker": {
          "color": "#FECB52",
          "pattern": {
           "shape": ""
          }
         },
         "name": "for",
         "offsetgroup": "for",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          9991
         ],
         "xaxis": "x",
         "y": [
          "for"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "realdonaldtrump",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "realdonaldtrump",
         "offsetgroup": "realdonaldtrump",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          8638
         ],
         "xaxis": "x",
         "y": [
          "realdonaldtrump"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "on",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "on",
         "offsetgroup": "on",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          8027
         ],
         "xaxis": "x",
         "y": [
          "on"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "s",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "s",
         "offsetgroup": "s",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          7394
         ],
         "xaxis": "x",
         "y": [
          "s"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "be",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "be",
         "offsetgroup": "be",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          6934
         ],
         "xaxis": "x",
         "y": [
          "be"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "it",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "it",
         "offsetgroup": "it",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          6837
         ],
         "xaxis": "x",
         "y": [
          "it"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "great",
         "marker": {
          "color": "#19d3f3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "great",
         "offsetgroup": "great",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          6755
         ],
         "xaxis": "x",
         "y": [
          "great"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "will",
         "marker": {
          "color": "#FF6692",
          "pattern": {
           "shape": ""
          }
         },
         "name": "will",
         "offsetgroup": "will",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          6678
         ],
         "xaxis": "x",
         "y": [
          "will"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "that",
         "marker": {
          "color": "#B6E880",
          "pattern": {
           "shape": ""
          }
         },
         "name": "that",
         "offsetgroup": "that",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          6295
         ],
         "xaxis": "x",
         "y": [
          "that"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "are",
         "marker": {
          "color": "#FF97FF",
          "pattern": {
           "shape": ""
          }
         },
         "name": "are",
         "offsetgroup": "are",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          5672
         ],
         "xaxis": "x",
         "y": [
          "are"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "trump",
         "marker": {
          "color": "#FECB52",
          "pattern": {
           "shape": ""
          }
         },
         "name": "trump",
         "offsetgroup": "trump",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          5604
         ],
         "xaxis": "x",
         "y": [
          "trump"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 700,
        "legend": {
         "title": {
          "text": "Common_words"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Common Words in Selected Text"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "trump",
          "are",
          "that",
          "will",
          "great",
          "it",
          "be",
          "s",
          "on",
          "realdonaldtrump",
          "for",
          "you",
          "i",
          "in",
          "is",
          "of",
          "a",
          "and",
          "to",
          "the"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Common_words"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d783b306-8cc4-48f9-8f0c-f9d707199912\" class=\"plotly-graph-div\" style=\"height:700px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d783b306-8cc4-48f9-8f0c-f9d707199912\")) {                    Plotly.newPlot(                        \"d783b306-8cc4-48f9-8f0c-f9d707199912\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"the\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"the\",\"offsetgroup\":\"the\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[34657],\"xaxis\":\"x\",\"y\":[\"the\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"to\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"to\",\"offsetgroup\":\"to\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[19801],\"xaxis\":\"x\",\"y\":[\"to\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"and\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"and\",\"offsetgroup\":\"and\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[15928],\"xaxis\":\"x\",\"y\":[\"and\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"a\",\"marker\":{\"color\":\"#ab63fa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"a\",\"offsetgroup\":\"a\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[15491],\"xaxis\":\"x\",\"y\":[\"a\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"of\",\"marker\":{\"color\":\"#FFA15A\",\"pattern\":{\"shape\":\"\"}},\"name\":\"of\",\"offsetgroup\":\"of\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[13345],\"xaxis\":\"x\",\"y\":[\"of\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"is\",\"marker\":{\"color\":\"#19d3f3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"is\",\"offsetgroup\":\"is\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[12886],\"xaxis\":\"x\",\"y\":[\"is\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"in\",\"marker\":{\"color\":\"#FF6692\",\"pattern\":{\"shape\":\"\"}},\"name\":\"in\",\"offsetgroup\":\"in\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[11942],\"xaxis\":\"x\",\"y\":[\"in\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"i\",\"marker\":{\"color\":\"#B6E880\",\"pattern\":{\"shape\":\"\"}},\"name\":\"i\",\"offsetgroup\":\"i\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[10795],\"xaxis\":\"x\",\"y\":[\"i\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"you\",\"marker\":{\"color\":\"#FF97FF\",\"pattern\":{\"shape\":\"\"}},\"name\":\"you\",\"offsetgroup\":\"you\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[10716],\"xaxis\":\"x\",\"y\":[\"you\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"for\",\"marker\":{\"color\":\"#FECB52\",\"pattern\":{\"shape\":\"\"}},\"name\":\"for\",\"offsetgroup\":\"for\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[9991],\"xaxis\":\"x\",\"y\":[\"for\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"realdonaldtrump\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"realdonaldtrump\",\"offsetgroup\":\"realdonaldtrump\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[8638],\"xaxis\":\"x\",\"y\":[\"realdonaldtrump\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"on\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"on\",\"offsetgroup\":\"on\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[8027],\"xaxis\":\"x\",\"y\":[\"on\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"s\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"s\",\"offsetgroup\":\"s\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[7394],\"xaxis\":\"x\",\"y\":[\"s\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"be\",\"marker\":{\"color\":\"#ab63fa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"be\",\"offsetgroup\":\"be\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[6934],\"xaxis\":\"x\",\"y\":[\"be\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"it\",\"marker\":{\"color\":\"#FFA15A\",\"pattern\":{\"shape\":\"\"}},\"name\":\"it\",\"offsetgroup\":\"it\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[6837],\"xaxis\":\"x\",\"y\":[\"it\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"great\",\"marker\":{\"color\":\"#19d3f3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"great\",\"offsetgroup\":\"great\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[6755],\"xaxis\":\"x\",\"y\":[\"great\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"will\",\"marker\":{\"color\":\"#FF6692\",\"pattern\":{\"shape\":\"\"}},\"name\":\"will\",\"offsetgroup\":\"will\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[6678],\"xaxis\":\"x\",\"y\":[\"will\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"that\",\"marker\":{\"color\":\"#B6E880\",\"pattern\":{\"shape\":\"\"}},\"name\":\"that\",\"offsetgroup\":\"that\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[6295],\"xaxis\":\"x\",\"y\":[\"that\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"are\",\"marker\":{\"color\":\"#FF97FF\",\"pattern\":{\"shape\":\"\"}},\"name\":\"are\",\"offsetgroup\":\"are\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[5672],\"xaxis\":\"x\",\"y\":[\"are\"],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Common_words=%{y}<br>count=%{x}<extra></extra>\",\"legendgroup\":\"trump\",\"marker\":{\"color\":\"#FECB52\",\"pattern\":{\"shape\":\"\"}},\"name\":\"trump\",\"offsetgroup\":\"trump\",\"orientation\":\"h\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[5604],\"xaxis\":\"x\",\"y\":[\"trump\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Common_words\"},\"categoryorder\":\"array\",\"categoryarray\":[\"trump\",\"are\",\"that\",\"will\",\"great\",\"it\",\"be\",\"s\",\"on\",\"realdonaldtrump\",\"for\",\"you\",\"i\",\"in\",\"is\",\"of\",\"a\",\"and\",\"to\",\"the\"]},\"legend\":{\"title\":{\"text\":\"Common_words\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Common Words in Selected Text\"},\"barmode\":\"relative\",\"height\":700,\"width\":700},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d783b306-8cc4-48f9-8f0c-f9d707199912');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Common Words in Selected Text', orientation='h', \n",
    "          width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "threatened-robert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mpipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, return_all_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbefore\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pmodel \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mTransformersPipeline(classifier, rescale_to_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m      6\u001b[0m explainer2 \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(pmodel)\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:125\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m        If `self.return_all_scores=True`, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;66;03m# This pipeline is odd, and return a list when single item is run\u001b[39;00m\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [result]\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\base.py:1015\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1012\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1013\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[1;32m-> 1015\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [output \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_iterator]\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\base.py:1015\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1012\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1013\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[1;32m-> 1015\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [output \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_iterator]\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:111\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:111\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:17\u001b[0m, in \u001b[0;36mPipelineDataset.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m     16\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[i]\n\u001b[1;32m---> 17\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:134\u001b[0m, in \u001b[0;36mTextClassificationPipeline.preprocess\u001b[1;34m(self, inputs, **tokenizer_kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, GenericTensor]:\n\u001b[0;32m    133\u001b[0m     return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(inputs, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2451\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2448\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[1;32m-> 2451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2454\u001b[0m     )\n\u001b[0;32m   2456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = transformers.pipeline('sentiment-analysis', return_all_scores=True)\n",
    "classifier(before[0])\n",
    "\n",
    "pmodel = shap.models.TransformersPipeline(classifier, rescale_to_logits=True) \n",
    "\n",
    "explainer2 = shap.Explainer(pmodel)\n",
    "shap_values = explainer2(before[0])\n",
    "shap.plots.text(shap_values[:,:,1])\n",
    "\n",
    "for i in range(n):\n",
    "    shap.plots.bar(shap_values[i, :,\"POSITIVE\"])\n",
    "shap.plots.bar(shap_values[:, :, \"POSITIVE\"].mean(0))\n",
    "shap.plots.bar(shap_values[:, :, \"POSITIVE\"].mean(0), order=shap.Explanation.argsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "thousand-palace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextInputSequence must be str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mpipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, return_all_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m cl \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mafter\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pmodel \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mTransformersPipeline(classifier, rescale_to_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m explainer2 \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(pmodel)\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:125\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m        If `self.return_all_scores=True`, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;66;03m# This pipeline is odd, and return a list when single item is run\u001b[39;00m\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [result]\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\base.py:1015\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1012\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1013\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[1;32m-> 1015\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [output \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_iterator]\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\base.py:1015\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1012\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1013\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[1;32m-> 1015\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [output \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_iterator]\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:111\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:111\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:17\u001b[0m, in \u001b[0;36mPipelineDataset.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m     16\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[i]\n\u001b[1;32m---> 17\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:134\u001b[0m, in \u001b[0;36mTextClassificationPipeline.preprocess\u001b[1;34m(self, inputs, **tokenizer_kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, GenericTensor]:\n\u001b[0;32m    133\u001b[0m     return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(inputs, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2477\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2474\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2475\u001b[0m         )\n\u001b[0;32m   2476\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 2477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2478\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2479\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2480\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2481\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2482\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2483\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2484\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2485\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2486\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2487\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2488\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2489\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2490\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2491\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2492\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2493\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2494\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2495\u001b[0m     )\n\u001b[0;32m   2496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2498\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2499\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2515\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2516\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2668\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2658\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2659\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2660\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2661\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2666\u001b[0m )\n\u001b[1;32m-> 2668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m   2669\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2670\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2671\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2672\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2673\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2674\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2675\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2676\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2677\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2678\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2679\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2680\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2681\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2682\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2683\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2684\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2686\u001b[0m )\n",
      "File \u001b[1;32m~\\PycharmProjects\\shapProjekt\\WFiIS-MIO-main\\env\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:425\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    418\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m    419\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    423\u001b[0m )\n\u001b[1;32m--> 425\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    437\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[0;32m    439\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[0;32m    449\u001b[0m ]\n",
      "\u001b[1;31mTypeError\u001b[0m: TextInputSequence must be str"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = transformers.pipeline('sentiment-analysis', return_all_scores=True)\n",
    "classifier(after[0])\n",
    "\n",
    "pmodel = shap.models.TransformersPipeline(classifier, rescale_to_logits=True)\n",
    "\n",
    "explainer2 = shap.Explainer(pmodel)\n",
    "shap_values = explainer2(after[0])\n",
    "shap.plots.text(shap_values[:,:,1])\n",
    "\n",
    "for i in range(n):\n",
    "    shap.plots.bar(shap_values[i, :,\"POSITIVE\"])\n",
    "shap.plots.bar(shap_values[:, :, \"POSITIVE\"].mean(0))\n",
    "shap.plots.bar(shap_values[:, :, \"POSITIVE\"].mean(0), order=shap.Explanation.argsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dangerous-albany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04369382860839609\n"
     ]
    }
   ],
   "source": [
    "average = sum(shap_values[:, :, \"POSITIVE\"].mean(0).values)/len(shap_values[:, :, \"POSITIVE\"].mean(0).values)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "polish-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative, positive = np.zeros((train.shape[0], 1)), np.zeros((train.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "answering-genre",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<transformers.pipelines.text_classification.TextClassificationPipeline object at 0x00000186BB843D30> argument after ** must be a mapping, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(after[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 2\u001b[0m     output \u001b[38;5;241m=\u001b[39m classifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtweet)\n\u001b[0;32m      3\u001b[0m     score \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m softmax(score)\n",
      "\u001b[1;31mTypeError\u001b[0m: <transformers.pipelines.text_classification.TextClassificationPipeline object at 0x00000186BB843D30> argument after ** must be a mapping, not list"
     ]
    }
   ],
   "source": [
    "for i, tweet in enumerate(after[0]):\n",
    "    output = classifier(*tweet)\n",
    "    score = output[0][0].detach().numpy()\n",
    "    scores = softmax(score)\n",
    "    negative[i] = scores[0]\n",
    "    positive[i] = scores[2]\n",
    "\n",
    "train['Negative'] = negative\n",
    "train['Positive'] = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-charles",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
